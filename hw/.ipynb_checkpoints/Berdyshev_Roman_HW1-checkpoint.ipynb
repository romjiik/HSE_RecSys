{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "63151877",
   "metadata": {},
   "source": [
    "## <center> RecSys. Home Assignment 1</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c581a7d",
   "metadata": {},
   "source": [
    "Один из важных навыков для построения рекомендательных систем - это умение корректно считать метрики качества ранжирования.\n",
    "\n",
    "В этой домашке вам нужно потренироваться в этом и имплементировать метрики Precision@k, Recall@k, MNAP@k и NDCG@k по формулам, чтобы дальше переиспользовать при построении своих рекомендательных моделей. \n",
    "\n",
    "Критерии оценивания:\n",
    "* Что-то пытался сделать, дописал свой код, но ничего не получилось - 1 балл. \n",
    "* Не совсем корректная имплементация одной из 4 метрик, прохождение части тестов - 1 балл. \n",
    "* Корректная имплементация одной из 4 метрик, прохождение всех тестов - 2 балла. \n",
    "* +1 балл, если получится написать Precision@k, Recall@k без циклов.\n",
    "* +1 балл, если получится написать NDCG@k, MNAP@k без циклов.\n",
    "\n",
    "Дедлайн сдачи - **24 октября 23:59**. \n",
    "\n",
    "Формат сдачи - отправить Jupyter notebook на почту ananyeva.me@gmail.com с темой письма \"[RecSys HW1]\" и названием файла [Name_Surname]_HW1.ipynb.  \n",
    "\n",
    "Удачи!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6c928452-693b-4a9d-bc66-284765b6ec50",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import NamedTuple, Union\n",
    "import tests\n",
    "import tests2\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c182c478",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "93c1466c-0e00-42ee-9e6d-f822da820a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrepareTargetResult(NamedTuple):\n",
    "    values: torch.Tensor\n",
    "    indices: torch.Tensor\n",
    "\n",
    "\n",
    "def validate_metric_inputs(output: torch.Tensor, target: torch.Tensor) -> None:\n",
    "    if output.size() != target.size():\n",
    "        raise IndexError(\n",
    "            \"Unequal sizes for output and target: \"\n",
    "            f\"output - {output.size()}, target - {target.size()}.\"\n",
    "        )\n",
    "    if not (target.eq(0) | target.eq(1)).all():\n",
    "        raise ValueError(\n",
    "            \"Target contains values outside of 0 and 1.\" f\"\\nTarget:\\n{target}\"\n",
    "        )\n",
    "\n",
    "\n",
    "def prepare_target(\n",
    "    output: torch.Tensor, target: torch.Tensor, return_indices: bool = False\n",
    ") -> Union[torch.Tensor, PrepareTargetResult]:\n",
    "    validate_metric_inputs(output, target)\n",
    "    # Define order by sorted output scores.\n",
    "    indices = output.argsort(dim=-1, descending=True)\n",
    "    sorted_target = torch.gather(target, index=indices, dim=-1)\n",
    "    return (\n",
    "        PrepareTargetResult(sorted_target, indices) if return_indices else sorted_target\n",
    "    )\n",
    "\n",
    "\n",
    "def nan_to_num(tensor: torch.Tensor, nan: float = 0.0) -> torch.Tensor:\n",
    "    return torch.where(\n",
    "        torch.isnan(tensor) | torch.isinf(tensor),\n",
    "        torch.full_like(tensor, fill_value=nan),\n",
    "        tensor,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b41fe1-8811-477d-8908-f1ab0d9547b6",
   "metadata": {},
   "source": [
    "# Precision\n",
    "\n",
    "$$P@k = \\frac{1}{k} \\sum_{i=1}^k [y_{i} = 1]$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "679e4cb5-0fde-43e6-92ff-de003a18057a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision(output: torch.Tensor, target: torch.Tensor, topk: int) -> torch.Tensor:\n",
    "    '''\n",
    "    output, target ~ (users, items)\n",
    "    target_sorted_by_output ~ (users, items)\n",
    "    '''\n",
    "    target_sorted_by_output = prepare_target(output, target)\n",
    "    precision_at_k = torch.mean(target_sorted_by_output[:, :topk])\n",
    "    return precision_at_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a600b149-385b-40ad-b97d-b016426a4e17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'output': tensor([[0., 0., 0., 0.]]), 'target': tensor([[0., 0., 0., 0.]]), 'topk': [1, 3, 10, 100], 'expected': {1: 0.0, 3: 0.0, 10: 0.0, 100: 0.0}}\n",
      "{'output': tensor([[1., 1., 1., 1.]]), 'target': tensor([[1., 1., 1., 1.]]), 'topk': [1, 3, 10, 100], 'expected': {1: 1.0, 3: 1.0, 10: 1.0, 100: 1.0}}\n",
      "{'output': tensor([[0., 0., 0., 0.]]), 'target': tensor([[1., 1., 1., 1.]]), 'topk': [1, 3, 10, 100], 'expected': {1: 1.0, 3: 1.0, 10: 1.0, 100: 1.0}}\n",
      "{'output': tensor([[1., 1., 1., 1.]]), 'target': tensor([[0., 0., 0., 0.]]), 'topk': [1, 3, 10, 100], 'expected': {1: 0.0, 3: 0.0, 10: 0.0, 100: 0.0}}\n",
      "{'output': tensor([[0.5000, 0.4000, 0.3000, 0.2000]]), 'target': tensor([[1., 0., 1., 0.]]), 'topk': [1, 3, 10, 100], 'expected': {1: 1.0, 3: 0.6666666666666666, 10: 0.5, 100: 0.5}}\n",
      "{'output': tensor([[ 9.,  5.,  3.,  0.,  7.,  4.,  0.,  0.,  6.,  0.,  0.,  0.,  0.,  0.,\n",
      "          0.,  1.,  8.,  2.,  0., 10.],\n",
      "        [ 0.,  0.,  1.,  5.,  9.,  3.,  0.,  0.,  0.,  0.,  0.,  4.,  0.,  0.,\n",
      "         10.,  7.,  0.,  2.,  8.,  6.],\n",
      "        [ 0.,  1.,  4.,  8.,  6.,  5.,  3.,  7., 10.,  0.,  9.,  0.,  0.,  2.,\n",
      "          0.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 7.,  8.,  0.,  0.,  1.,  0.,  4.,  0., 10.,  0.,  0.,  6.,  0.,  0.,\n",
      "          0.,  9.,  2.,  3.,  5.,  0.]]), 'target': tensor([[1., 1., 1., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0.,\n",
      "         1., 0.],\n",
      "        [1., 0., 1., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 1., 0., 1., 1.,\n",
      "         0., 0.],\n",
      "        [0., 0., 0., 0., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 0., 1.,\n",
      "         1., 0.],\n",
      "        [0., 1., 1., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 0., 1., 0., 0., 1.,\n",
      "         0., 0.]]), 'topk': [1, 3, 10, 100], 'expected': {1: 0.25, 3: 0.41666666666666663, 10: 0.4, 100: 0.4375}}\n"
     ]
    }
   ],
   "source": [
    "tests.run_precision(precision)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a057208-db6d-48cf-b5e1-7203efe94e1c",
   "metadata": {},
   "source": [
    "# Recall\n",
    "\n",
    "$$R@k = \\frac{\\sum_{i=1}^k [y_{i} = 1]}{\\sum_{i=1}^N [y_{i} = 1]}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d67da32b-2e3a-4e1d-a3df-1f32d117b95b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall(output: torch.Tensor, target: torch.Tensor, topk: int) -> torch.Tensor:\n",
    "    '''\n",
    "    output, target ~ (users, items)\n",
    "    target_sorted_by_output ~ (users, items)\n",
    "    '''\n",
    "    target_sorted_by_output = prepare_target(output, target)\n",
    "    if torch.sum(target_sorted_by_output) == 0:\n",
    "        recall_at_k = 0.\n",
    "    else:\n",
    "        recall_at_k = torch.mean(torch.sum(target_sorted_by_output[:, :topk], dim=-1) /  torch.sum(target_sorted_by_output, dim=-1))\n",
    "    return recall_at_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e77cb6cc-2ca7-483a-abe9-75cbaf92539c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'output': tensor([[0., 0., 0., 0.]]), 'target': tensor([[0., 0., 0., 0.]]), 'topk': [1, 3, 10, 100], 'expected': {1: 0.0, 3: 0.0, 10: 0.0, 100: 0.0}}\n",
      "{'output': tensor([[1., 1., 1., 1.]]), 'target': tensor([[1., 1., 1., 1.]]), 'topk': [1, 3, 10, 100], 'expected': {1: 0.25, 3: 0.75, 10: 1.0, 100: 1.0}}\n",
      "{'output': tensor([[0., 0., 0., 0.]]), 'target': tensor([[1., 1., 1., 1.]]), 'topk': [1, 3, 10, 100], 'expected': {1: 0.25, 3: 0.75, 10: 1.0, 100: 1.0}}\n",
      "{'output': tensor([[1., 1., 1., 1.]]), 'target': tensor([[0., 0., 0., 0.]]), 'topk': [1, 3, 10, 100], 'expected': {1: 0.0, 3: 0.0, 10: 0.0, 100: 0.0}}\n",
      "{'output': tensor([[0.5000, 0.4000, 0.3000, 0.2000]]), 'target': tensor([[1., 0., 1., 0.]]), 'topk': [1, 3, 10, 100], 'expected': {1: 0.5, 3: 1.0, 10: 1.0, 100: 1.0}}\n",
      "{'output': tensor([[ 9.,  5.,  3.,  0.,  7.,  4.,  0.,  0.,  6.,  0.,  0.,  0.,  0.,  0.,\n",
      "          0.,  1.,  8.,  2.,  0., 10.],\n",
      "        [ 0.,  0.,  1.,  5.,  9.,  3.,  0.,  0.,  0.,  0.,  0.,  4.,  0.,  0.,\n",
      "         10.,  7.,  0.,  2.,  8.,  6.],\n",
      "        [ 0.,  1.,  4.,  8.,  6.,  5.,  3.,  7., 10.,  0.,  9.,  0.,  0.,  2.,\n",
      "          0.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 7.,  8.,  0.,  0.,  1.,  0.,  4.,  0., 10.,  0.,  0.,  6.,  0.,  0.,\n",
      "          0.,  9.,  2.,  3.,  5.,  0.]]), 'target': tensor([[1., 1., 1., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0.,\n",
      "         1., 0.],\n",
      "        [1., 0., 1., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 1., 0., 1., 1.,\n",
      "         0., 0.],\n",
      "        [0., 0., 0., 0., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 0., 1.,\n",
      "         1., 0.],\n",
      "        [0., 1., 1., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 0., 1., 0., 0., 1.,\n",
      "         0., 0.]]), 'topk': [1, 3, 10, 100], 'expected': {1: 0.03125, 3: 0.14652777777777776, 10: 0.4583333333333333, 100: 1.0}}\n"
     ]
    }
   ],
   "source": [
    "tests.run_recall(recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6362e92-6ad3-441e-ab38-bd931348e920",
   "metadata": {},
   "source": [
    "# Mean (Normalized) Average Precision\n",
    "\n",
    "\n",
    "$$AP@k = \\sum_{i=1}^{k} \\frac{y_{i}}{\\sum_{j=1}^{k} \\cdot y_{j}} p@i$$\n",
    "$$MNAP@k = \\frac{1}{U} \\sum_{u \\in U} \\frac{1}{min(k, n_u)} AP@k_{u},$$\n",
    "\n",
    "где $n_u$ - количество айтемов с интеракциями у пользователя $u$ в тестовый период, <br>\n",
    "$U$ - количество пользователей. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1daf876a-4b0b-48af-a38d-57423e5ff46d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def mnap(output: torch.Tensor, target: torch.Tensor, topk: int, normalized: bool = True) -> torch.Tensor:\n",
    "#     '''\n",
    "#     output, target ~ (users, items)\n",
    "#     target_sorted_by_output ~ (users, items)\n",
    "#     '''\n",
    "#     target_sorted_by_output = prepare_target(output, target)\n",
    "#     res = 0.\n",
    "#     if normalized:\n",
    "#         for i in range(min(topk, target_sorted_by_output.shape[1])):\n",
    "#             res += torch.mean(\n",
    "#                                 torch.nan_to_num(\n",
    "#                                     1 / min(topk, torch.sum(target_sorted_by_output, dim=-1)) * \\\n",
    "#                                     target_sorted_by_output[:, i] * \\\n",
    "#                                     torch.mean(target_sorted_by_output[:, :i+1], dim=-1) / \\\n",
    "#                                     torch.sum(target_sorted_by_output[:, :topk], dim=-1)\n",
    "#                                 )\n",
    "#                     )\n",
    "# #         print(res)\n",
    "            \n",
    "#     else:\n",
    "#         for i in range(min(topk, target_sorted_by_output.shape[1])):\n",
    "# #             if torch.sum(target_sorted_by_output[:, :topk]) != 0:\n",
    "#             res += torch.mean(torch.nan_to_num(target_sorted_by_output[:, i] * \\\n",
    "#                                         torch.mean(target_sorted_by_output[:, :i+1], dim=-1) / \\\n",
    "#                                         torch.sum(target_sorted_by_output[:, :topk], dim=-1)))\n",
    "# #                 print(f\"precision_at_{i} = {torch.mean(target_sorted_by_output[:, :i+1], dim=-1)}\")\n",
    "# #                 print(f\"y_i = {target_sorted_by_output[:, i]}\")\n",
    "# #                 print(f\"sum y_i = {torch.sum(target_sorted_by_output[:, :topk], dim=-1)}\")\n",
    "# #         print(ap_at_k.shape)\n",
    "# #         print(ap_at_k)\n",
    "#     return res\n",
    "#     # YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6ccb0fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mnap(output: torch.Tensor, target: torch.Tensor, topk: int, normalized: bool = True) -> torch.Tensor:\n",
    "    '''\n",
    "    output, target ~ (users, items)\n",
    "    target_sorted_by_output ~ (users, items)\n",
    "    '''\n",
    "    target_sorted_by_output = prepare_target(output, target)\n",
    "    res = 0.\n",
    "    if normalized:\n",
    "        min_ = torch.min(\n",
    "            torch.full_like(torch.sum(target_sorted_by_output, dim=-1), topk),\n",
    "            torch.sum(target_sorted_by_output, dim=-1)\n",
    "        )\n",
    "        res = torch.mean(torch.nan_to_num(1 / min_ * torch.sum((target_sorted_by_output * \\\n",
    "                                (torch.cumsum(target_sorted_by_output, dim=-1) / \\\n",
    "                                torch.tensor(range(1, target_sorted_by_output.shape[1] + 1))))[:, : topk], dim=-1)))\n",
    "    else:\n",
    "        res = torch.mean(torch.nan_to_num(torch.sum((target_sorted_by_output * (target_sorted_by_output.cumsum(dim=-1) / \\\n",
    "                                    torch.tensor(range(1, target_sorted_by_output.shape[1] + 1))))[:, : topk], dim=-1) / \\\n",
    "                                torch.sum(target_sorted_by_output[:, : topk], dim=-1)))           \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e661719b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'output': tensor([[0., 0., 0., 0.]]), 'target': tensor([[0., 0., 0., 0.]]), 'topk': [1, 3, 10, 100], 'expected': {1: 0.0, 3: 0.0, 10: 0.0, 100: 0.0}}\n",
      "{'output': tensor([[1., 1., 1., 1.]]), 'target': tensor([[1., 1., 1., 1.]]), 'topk': [1, 3, 10, 100], 'expected': {1: 1.0, 3: 1.0, 10: 1.0, 100: 1.0}}\n",
      "{'output': tensor([[0., 0., 0., 0.]]), 'target': tensor([[1., 1., 1., 1.]]), 'topk': [1, 3, 10, 100], 'expected': {1: 1.0, 3: 1.0, 10: 1.0, 100: 1.0}}\n",
      "{'output': tensor([[1., 1., 1., 1.]]), 'target': tensor([[0., 0., 0., 0.]]), 'topk': [1, 3, 10, 100], 'expected': {1: 0.0, 3: 0.0, 10: 0.0, 100: 0.0}}\n",
      "{'output': tensor([[ 9.,  5.,  3.,  0.,  7.,  4.,  0.,  0.,  6.,  0.,  0.,  0.,  0.,  0.,\n",
      "          0.,  1.,  8.,  2.,  0., 10.],\n",
      "        [ 0.,  0.,  1.,  5.,  9.,  3.,  0.,  0.,  0.,  0.,  0.,  4.,  0.,  0.,\n",
      "         10.,  7.,  0.,  2.,  8.,  6.],\n",
      "        [ 0.,  1.,  4.,  8.,  6.,  5.,  3.,  7., 10.,  0.,  9.,  0.,  0.,  2.,\n",
      "          0.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 7.,  8.,  0.,  0.,  1.,  0.,  4.,  0., 10.,  0.,  0.,  6.,  0.,  0.,\n",
      "          0.,  9.,  2.,  3.,  5.,  0.]]), 'target': tensor([[1., 1., 1., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0.,\n",
      "         1., 0.],\n",
      "        [1., 0., 1., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 1., 0., 1., 1.,\n",
      "         0., 0.],\n",
      "        [0., 0., 0., 0., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 0., 1.,\n",
      "         1., 0.],\n",
      "        [0., 1., 1., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 0., 1., 0., 0., 1.,\n",
      "         0., 0.]]), 'topk': [1], 'expected': {1: 0.25}}\n",
      "{'output': tensor([[0., 0., 0., 0.]]), 'target': tensor([[0., 0., 0., 0.]]), 'topk': [1, 3, 10, 100], 'expected': {1: 0.0, 3: 0.0, 10: 0.0, 100: 0.0}}\n",
      "{'output': tensor([[1., 1., 1., 1.]]), 'target': tensor([[1., 1., 1., 1.]]), 'topk': [1, 3, 10, 100], 'expected': {1: 1.0, 3: 1.0, 10: 1.0, 100: 1.0}}\n",
      "{'output': tensor([[0., 0., 0., 0.]]), 'target': tensor([[1., 1., 1., 1.]]), 'topk': [1, 3, 10, 100], 'expected': {1: 1.0, 3: 1.0, 10: 1.0, 100: 1.0}}\n",
      "{'output': tensor([[1., 1., 1., 1.]]), 'target': tensor([[0., 0., 0., 0.]]), 'topk': [1, 3, 10, 100], 'expected': {1: 0.0, 3: 0.0, 10: 0.0, 100: 0.0}}\n",
      "{'output': tensor([[0.5000, 0.4000, 0.3000, 0.2000]]), 'target': tensor([[1., 0., 1., 0.]]), 'topk': [1, 3, 10, 100], 'expected': {1: 1.0, 3: 0.8333333333333333, 10: 0.8333333333333333, 100: 0.8333333333333333}}\n",
      "{'output': tensor([[ 9.,  5.,  3.,  0.,  7.,  4.,  0.,  0.,  6.,  0.,  0.,  0.,  0.,  0.,\n",
      "          0.,  1.,  8.,  2.,  0., 10.],\n",
      "        [ 0.,  0.,  1.,  5.,  9.,  3.,  0.,  0.,  0.,  0.,  0.,  4.,  0.,  0.,\n",
      "         10.,  7.,  0.,  2.,  8.,  6.],\n",
      "        [ 0.,  1.,  4.,  8.,  6.,  5.,  3.,  7., 10.,  0.,  9.,  0.,  0.,  2.,\n",
      "          0.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 7.,  8.,  0.,  0.,  1.,  0.,  4.,  0., 10.,  0.,  0.,  6.,  0.,  0.,\n",
      "          0.,  9.,  2.,  3.,  5.,  0.]]), 'target': tensor([[1., 1., 1., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0.,\n",
      "         1., 0.],\n",
      "        [1., 0., 1., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 1., 0., 1., 1.,\n",
      "         0., 0.],\n",
      "        [0., 0., 0., 0., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 0., 1.,\n",
      "         1., 0.],\n",
      "        [0., 1., 1., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 0., 1., 0., 0., 1.,\n",
      "         0., 0.]]), 'topk': [1, 3, 10], 'expected': {1: 0.25, 3: 0.24999999999999994, 10: 0.23171709656084655}}\n"
     ]
    }
   ],
   "source": [
    "tests2.run_map(mnap)\n",
    "tests2.run_mnap(mnap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "39353a96-0ce9-493d-a56c-29c85759bf7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'output': tensor([[0., 0., 0., 0.]]), 'target': tensor([[0., 0., 0., 0.]]), 'topk': [1, 3, 10, 100], 'expected': {1: 0.0, 3: 0.0, 10: 0.0, 100: 0.0}}\n",
      "{'output': tensor([[1., 1., 1., 1.]]), 'target': tensor([[1., 1., 1., 1.]]), 'topk': [1, 3, 10, 100], 'expected': {1: 1.0, 3: 1.0, 10: 1.0, 100: 1.0}}\n",
      "{'output': tensor([[0., 0., 0., 0.]]), 'target': tensor([[1., 1., 1., 1.]]), 'topk': [1, 3, 10, 100], 'expected': {1: 1.0, 3: 1.0, 10: 1.0, 100: 1.0}}\n",
      "{'output': tensor([[1., 1., 1., 1.]]), 'target': tensor([[0., 0., 0., 0.]]), 'topk': [1, 3, 10, 100], 'expected': {1: 0.0, 3: 0.0, 10: 0.0, 100: 0.0}}\n",
      "{'output': tensor([[0.5000, 0.4000, 0.3000, 0.2000]]), 'target': tensor([[1., 0., 1., 0.]]), 'topk': [1, 3, 10, 100], 'expected': {1: 1.0, 3: 0.5555555555555555, 10: 0.41666666666666663, 100: 0.41666666666666663}}\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Inputs:{\n  \"output\": [\n    [\n      0.5,\n      0.4000000059604645,\n      0.30000001192092896,\n      0.20000000298023224\n    ]\n  ],\n  \"target\": [\n    [\n      1.0,\n      0.0,\n      1.0,\n      0.0\n    ]\n  ],\n  \"topk\": 3\n}\nScalars are not close!\n\nAbsolute difference: 0.2777777910232544 (up to 1e-05 allowed)\nRelative difference: 0.5 (up to 1.3e-06 allowed)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtests\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_map\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmnap\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m tests\u001b[38;5;241m.\u001b[39mrun_mnap(mnap)\n",
      "File \u001b[0;32m~/Documents/Programs/HSE/HSE_RecSys/hw/tests.py:278\u001b[0m, in \u001b[0;36mrun_map\u001b[0;34m(func)\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_map\u001b[39m(func: Callable) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    181\u001b[0m     cases \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    182\u001b[0m         {\n\u001b[1;32m    183\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput\u001b[39m\u001b[38;5;124m\"\u001b[39m: torch\u001b[38;5;241m.\u001b[39mTensor([[\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m]]),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    276\u001b[0m         },\n\u001b[1;32m    277\u001b[0m     ]\n\u001b[0;32m--> 278\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_run_tests\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnormalized\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcases\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Programs/HSE/HSE_RecSys/hw/tests.py:489\u001b[0m, in \u001b[0;36m_run_tests\u001b[0;34m(func, cases)\u001b[0m\n\u001b[1;32m    487\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m case\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtopk\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    488\u001b[0m     actual \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcase, topk\u001b[38;5;241m=\u001b[39mk)\n\u001b[0;32m--> 489\u001b[0m     \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtesting\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43massert_close\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    490\u001b[0m \u001b[43m        \u001b[49m\u001b[43mactual\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    491\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexpected\u001b[49m\u001b[43m[\u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mactual\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTensor\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mexpected\u001b[49m\u001b[43m[\u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    492\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmsg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mInputs:\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdumps\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;250;43m \u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtolist\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;250;43m \u001b[39;49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[38;5;250;43m \u001b[39;49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;250;43m \u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTensor\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;250;43m \u001b[39;49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[38;5;250;43m \u001b[39;49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;250;43m \u001b[39;49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[38;5;250;43m \u001b[39;49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;250;43m \u001b[39;49m\u001b[43mv\u001b[49m\u001b[38;5;250;43m \u001b[39;49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[38;5;250;43m \u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcase\u001b[49m\u001b[38;5;250;43m \u001b[39;49m\u001b[38;5;241;43m|\u001b[39;49m\u001b[38;5;250;43m \u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtopk\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;250;43m \u001b[39;49m\u001b[43mk\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;250;43m \u001b[39;49m\u001b[43mindent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;250;43m \u001b[39;49m\u001b[43mensure_ascii\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mmsg\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/torch/testing/_comparison.py:1511\u001b[0m, in \u001b[0;36massert_close\u001b[0;34m(actual, expected, allow_subclasses, rtol, atol, equal_nan, check_device, check_dtype, check_layout, check_stride, msg)\u001b[0m\n\u001b[1;32m   1489\u001b[0m error_metas \u001b[38;5;241m=\u001b[39m not_close_error_metas(\n\u001b[1;32m   1490\u001b[0m     actual,\n\u001b[1;32m   1491\u001b[0m     expected,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1506\u001b[0m     msg\u001b[38;5;241m=\u001b[39mmsg,\n\u001b[1;32m   1507\u001b[0m )\n\u001b[1;32m   1509\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m error_metas:\n\u001b[1;32m   1510\u001b[0m     \u001b[38;5;66;03m# TODO: compose all metas into one AssertionError\u001b[39;00m\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m error_metas[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mto_error(msg)\n",
      "\u001b[0;31mAssertionError\u001b[0m: Inputs:{\n  \"output\": [\n    [\n      0.5,\n      0.4000000059604645,\n      0.30000001192092896,\n      0.20000000298023224\n    ]\n  ],\n  \"target\": [\n    [\n      1.0,\n      0.0,\n      1.0,\n      0.0\n    ]\n  ],\n  \"topk\": 3\n}\nScalars are not close!\n\nAbsolute difference: 0.2777777910232544 (up to 1e-05 allowed)\nRelative difference: 0.5 (up to 1.3e-06 allowed)"
     ]
    }
   ],
   "source": [
    "tests.run_map(mnap)\n",
    "tests.run_mnap(mnap)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aed91757-0350-4c0b-bd1f-6943793074ba",
   "metadata": {},
   "source": [
    "# Normalized Dicsounted Cumulative Gain\n",
    "\n",
    "\n",
    "$$ NDCG @k = \\frac{DCG@k}{IDCG@k},$$ где \n",
    "$$DCG@k = \\sum_{i=1}^{k} \\frac{2^{y_{i}} - 1}{log_2 (i + 1)}$$\n",
    "$$IDCG@k = \\sum_{i=1}^{k} \\frac{1}{log_2 (i + 1)}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "72610077-102a-4860-b65e-8f59e0a618e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dcg(tensor: torch.Tensor) -> torch.Tensor:\n",
    "    gains = (2**tensor) - 1\n",
    "    return gains / torch.log2(torch.arange(0, tensor.size(-1), dtype=torch.float, device=tensor.device) + 2.0)\n",
    "\n",
    "\n",
    "def ndcg(output: torch.Tensor, target: torch.Tensor, topk: int) -> torch.Tensor:\n",
    "    '''\n",
    "    output, target ~ (users, items)\n",
    "    target_sorted_by_output ~ (users, items)\n",
    "    '''\n",
    "    target_sorted_by_output = prepare_target(output, target)\n",
    "    ideal_target = prepare_target(target, target)\n",
    "    dcg_at_k = torch.sum(dcg(target_sorted_by_output[:, :topk]), dim=-1)\n",
    "    idcg_at_k = torch.sum(dcg(ideal_target[:, :topk]), dim=-1)\n",
    "    ndcg_at_k = torch.mean(torch.nan_to_num(dcg_at_k / idcg_at_k))\n",
    "    return ndcg_at_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "44fa9a52-19e5-4a15-8bb0-7c034655a689",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'output': tensor([[0., 0., 0., 0.]]), 'target': tensor([[0., 0., 0., 0.]]), 'topk': [1, 3, 10, 100], 'expected': {1: 0.0, 3: 0.0, 10: 0.0, 100: 0.0}}\n",
      "{'output': tensor([[1., 1., 1., 1.]]), 'target': tensor([[1., 1., 1., 1.]]), 'topk': [1, 3, 10, 100], 'expected': {1: 1.0, 3: 1.0, 10: 1.0, 100: 1.0}}\n",
      "{'output': tensor([[0., 0., 0., 0.]]), 'target': tensor([[1., 1., 1., 1.]]), 'topk': [1, 3, 10, 100], 'expected': {1: 1.0, 3: 1.0, 10: 1.0, 100: 1.0}}\n",
      "{'output': tensor([[1., 1., 1., 1.]]), 'target': tensor([[0., 0., 0., 0.]]), 'topk': [1, 3, 10, 100], 'expected': {1: 0.0, 3: 0.0, 10: 0.0, 100: 0.0}}\n",
      "{'output': tensor([[0.5000, 0.4000, 0.3000, 0.2000]]), 'target': tensor([[1., 0., 1., 0.]]), 'topk': [1, 3, 10, 100], 'expected': {1: 1.0, 3: 0.9197207891481876, 10: 0.9197207891481876, 100: 0.9197207891481876}}\n",
      "{'output': tensor([[ 9.,  5.,  3.,  0.,  7.,  4.,  0.,  0.,  6.,  0.,  0.,  0.,  0.,  0.,\n",
      "          0.,  1.,  8.,  2.,  0., 10.],\n",
      "        [ 0.,  0.,  1.,  5.,  9.,  3.,  0.,  0.,  0.,  0.,  0.,  4.,  0.,  0.,\n",
      "         10.,  7.,  0.,  2.,  8.,  6.],\n",
      "        [ 0.,  1.,  4.,  8.,  6.,  5.,  3.,  7., 10.,  0.,  9.,  0.,  0.,  2.,\n",
      "          0.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 7.,  8.,  0.,  0.,  1.,  0.,  4.,  0., 10.,  0.,  0.,  6.,  0.,  0.,\n",
      "          0.,  9.,  2.,  3.,  5.,  0.]]), 'target': tensor([[1., 1., 1., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0.,\n",
      "         1., 0.],\n",
      "        [1., 0., 1., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 1., 0., 1., 1.,\n",
      "         0., 0.],\n",
      "        [0., 0., 0., 0., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 0., 1.,\n",
      "         1., 0.],\n",
      "        [0., 1., 1., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 0., 1., 0., 0., 1.,\n",
      "         0., 0.]]), 'topk': [1, 3, 10, 100], 'expected': {1: 0.25, 3: 0.38268031849431083, 10: 0.418201508783155, 100: 0.6991580719431003}}\n"
     ]
    }
   ],
   "source": [
    "tests.run_ndcg(ndcg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c69c08",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "afdf057ef1ef2906fc2cc2ffd617646692fe5d919d63b76727650bd7046d9edf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
